{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3fa3c6-e494-4659-9f7c-0c69b0809cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=\"enter_openai_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5aa1d-7a55-4a77-839c-3f3ed8749b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=PyPDFLoader(\"file.pdf\") #file location in device\n",
    "page=pdf.load()\n",
    "#print(len(page)) \n",
    "split=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100)\n",
    "chunk=split.split_documents(page)\n",
    "#for i, ch in enumerate(chunk): \n",
    " #   print(f\"Chunk{i}:\\n\")\n",
    "  #  print(ch.page_content)\n",
    "   # print(\"----------\")\n",
    "embeddings=OpenAIEmbeddings()\n",
    "vect=FAISS.from_documents(chunk,embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437e7571-e994-4be5-bee5-213993768b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user:  my name is tushar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot: \n",
      "Hello Tushar, it's nice to meet you! I am an AI assistant designed to assist with tasks and have conversations in different languages. Is there something specific you would like to know or discuss?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user:  is the name tushar mentioned in the document\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot: \n",
      "Yes, the name Tushar is mentioned in the document. Tushar Sharma is listed as one of the authors and his email address is also included in the document. Is there anything else you would like to know about the document or Tushar?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user:  what is my name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot: \n",
      "Your name is Tushar, as mentioned in our previous conversation. Is there anything else you would like to know?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user:  exit\n"
     ]
    }
   ],
   "source": [
    "memory=ConversationBufferMemory(memory_key=\"history\",return_messages=True)\n",
    "prompt_template=\"\"\"\n",
    "you are an AI assistant with access to the document, you can also have a general conversation with the user in the language the user prefers : {content}\n",
    "you are also in an ongoing conversation and here is the context of the conversation so far: {history}\n",
    "respond to the following user question in a helpful and informative manner: {inp}\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=[\"content\",\"history\",\"inp\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "llm=OpenAI(temperature=0.7)\n",
    "\n",
    "def cbot(q):\n",
    "    s=vect.similarity_search(q)\n",
    "    c=\"\\n\\n\".join([doc.page_content for doc in s])\n",
    "    f=prompt.format(\n",
    "        content=c,\n",
    "        history=memory.load_memory_variables({})[\"history\"],\n",
    "        inp=q\n",
    "    )\n",
    "    response=llm(f)\n",
    "    memory.save_context({\"input\":q},{\"output\":response})\n",
    "    return response\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    while True:\n",
    "        inp=input(\"\\nuser: \")\n",
    "        if inp=='exit':\n",
    "            break\n",
    "        b=cbot(inp)\n",
    "        print(f\"chatbot: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f6381-a82d-4feb-a7de-f3dd93db267f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0733ab-141e-4be0-aaea-583227b0b457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
